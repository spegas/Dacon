{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get_Price_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPiuFk6sCvtZSyo3GOgZGc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spegas/Dacon/blob/main/Get_Price_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3J3S1HAswgc",
        "outputId": "1a9a0fdf-84f7-4d71-bf1c-f9adf7788661"
      },
      "source": [
        "!pip install finance-datareader"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting finance-datareader\n",
            "  Downloading finance_datareader-0.9.31-py3-none-any.whl (17 kB)\n",
            "Collecting requests-file\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.62.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (4.2.6)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.7/dist-packages (from finance-datareader) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.19.2->finance-datareader) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.19.2->finance-datareader) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.3.0->finance-datareader) (3.0.4)\n",
            "Installing collected packages: requests-file, finance-datareader\n",
            "Successfully installed finance-datareader-0.9.31 requests-file-1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDldBr3ttOwb",
        "outputId": "dddceb87-858a-45e6-9993-1bacedf4ed4e"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=0aac2173c28b79e092605c1f3de19f892fa6b78d1fd1a7c2d53fbe7a04fe7ab3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRl1AiHstGQ5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import FinanceDataReader as fdr\n",
        "import wget\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from os.path import basename"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDcJu5upvpml"
      },
      "source": [
        "if not os.path.isdir(\"base\"):\n",
        "  print(\"base 디렉토리 생성\")\n",
        "  os.makedirs(\"base\")\n",
        "\n",
        "if not os.path.isdir(\"price\"):\n",
        "  print(\"price 디렉토리 생성\")\n",
        "  os.makedirs(\"price\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdtUujcrvwKA",
        "outputId": "820829b7-c2e6-4eea-b557-2bbcdc4f8047"
      },
      "source": [
        "stock_list_file_url = \"https://raw.githubusercontent.com/spegas/Dacon/main/stock_list.csv\"\n",
        "if os.path.exists('base/stock_list.csv'):\n",
        "  os.remove('base/stock_list.csv')\n",
        "  print('이전에 저장된 주식 종목 리스트 파일을 삭제 합니다.')\n",
        "wget.download(stock_list_file_url, 'base/stock_list.csv')\n",
        "print('주식 종목 리스트 파일 다운로드 완료')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "주식 종목 리스트 파일 다운로드 완료\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTXwab-FwKxb"
      },
      "source": [
        "stock_list_name = 'base/stock_list.csv'\n",
        "pd_stock_list = pd.read_csv(stock_list_name)\n",
        "pd_stock_list['종목코드'] = pd_stock_list['종목코드'].apply(lambda x : str(x).zfill(6))\n",
        "pd_stock_list.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMPpBg6Mv0aY"
      },
      "source": [
        "start_date = '20200101'\n",
        "end_date = '20211031'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2ZDm_E6v4wH"
      },
      "source": [
        "for f_index in range(0, pd_stock_list.shape[0]):\n",
        "  f_code = pd_stock_list.iloc[f_index]['종목코드']\n",
        "  f_name = pd_stock_list.iloc[f_index]['종목명']\n",
        "  price_filename = str('price/') + str(f_code) + str('_price.csv')\n",
        "  if not os.path.exists(price_filename):\n",
        "    f_price = fdr.DataReader(f_code, start = start_date, end = end_date)\n",
        "    f_price.to_csv(price_filename)\n",
        "    print('[종목코드 : %s, 종목명 : %s] 가격 정보 저장 완료' % (str(f_code), str(f_name)))\n",
        "  else:\n",
        "    print('[종목코드 : %s, 종목명 : %s] 가격 정보 파일 존재' % (str(f_code), str(f_name)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSSO4jU-6WCd"
      },
      "source": [
        "# Zip the files from given directory that matches the filter\n",
        "def zipFilesInDir(dirName, zipFileName, filter):\n",
        "   # create a ZipFile object\n",
        "   with ZipFile(zipFileName, 'w') as zipObj:\n",
        "       # Iterate over all the files in directory\n",
        "       for folderName, subfolders, filenames in os.walk(dirName):\n",
        "           for filename in filenames:\n",
        "               if filter(filename):\n",
        "                   # create complete filepath of file in directory\n",
        "                   filePath = os.path.join(folderName, filename)\n",
        "                   # Add file to zip\n",
        "                   zipObj.write(filePath, basename(filePath))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lfaKaW_6ZF9"
      },
      "source": [
        "zipFilesInDir('price', 'price.zip', lambda name : 'csv' in name)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2puLLmGC4nh"
      },
      "source": [
        "pd_price = pd.read_csv('price/005830_price.csv')"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "DPJSzVPaDMys",
        "outputId": "f34b334d-079c-4f82-efa4-b48a6ba789bb"
      },
      "source": [
        "pd_price"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>52400</td>\n",
              "      <td>52600</td>\n",
              "      <td>50000</td>\n",
              "      <td>50100</td>\n",
              "      <td>194505</td>\n",
              "      <td>-0.042065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>50500</td>\n",
              "      <td>51300</td>\n",
              "      <td>50100</td>\n",
              "      <td>50800</td>\n",
              "      <td>246721</td>\n",
              "      <td>0.013972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>50800</td>\n",
              "      <td>50800</td>\n",
              "      <td>49900</td>\n",
              "      <td>50200</td>\n",
              "      <td>142825</td>\n",
              "      <td>-0.011811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-07</td>\n",
              "      <td>50500</td>\n",
              "      <td>50500</td>\n",
              "      <td>49450</td>\n",
              "      <td>49750</td>\n",
              "      <td>192139</td>\n",
              "      <td>-0.008964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-08</td>\n",
              "      <td>49250</td>\n",
              "      <td>49300</td>\n",
              "      <td>47950</td>\n",
              "      <td>48550</td>\n",
              "      <td>211203</td>\n",
              "      <td>-0.024121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>2021-10-25</td>\n",
              "      <td>66000</td>\n",
              "      <td>66900</td>\n",
              "      <td>65600</td>\n",
              "      <td>66400</td>\n",
              "      <td>75686</td>\n",
              "      <td>0.004539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>67100</td>\n",
              "      <td>67100</td>\n",
              "      <td>65400</td>\n",
              "      <td>66000</td>\n",
              "      <td>82375</td>\n",
              "      <td>-0.006024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>2021-10-27</td>\n",
              "      <td>65700</td>\n",
              "      <td>65900</td>\n",
              "      <td>64400</td>\n",
              "      <td>65300</td>\n",
              "      <td>116769</td>\n",
              "      <td>-0.010606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>2021-10-28</td>\n",
              "      <td>64900</td>\n",
              "      <td>65000</td>\n",
              "      <td>60600</td>\n",
              "      <td>60800</td>\n",
              "      <td>282584</td>\n",
              "      <td>-0.068913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>2021-10-29</td>\n",
              "      <td>60700</td>\n",
              "      <td>61500</td>\n",
              "      <td>58400</td>\n",
              "      <td>59200</td>\n",
              "      <td>302475</td>\n",
              "      <td>-0.026316</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date   Open   High    Low  Close  Volume    Change\n",
              "0    2020-01-02  52400  52600  50000  50100  194505 -0.042065\n",
              "1    2020-01-03  50500  51300  50100  50800  246721  0.013972\n",
              "2    2020-01-06  50800  50800  49900  50200  142825 -0.011811\n",
              "3    2020-01-07  50500  50500  49450  49750  192139 -0.008964\n",
              "4    2020-01-08  49250  49300  47950  48550  211203 -0.024121\n",
              "..          ...    ...    ...    ...    ...     ...       ...\n",
              "447  2021-10-25  66000  66900  65600  66400   75686  0.004539\n",
              "448  2021-10-26  67100  67100  65400  66000   82375 -0.006024\n",
              "449  2021-10-27  65700  65900  64400  65300  116769 -0.010606\n",
              "450  2021-10-28  64900  65000  60600  60800  282584 -0.068913\n",
              "451  2021-10-29  60700  61500  58400  59200  302475 -0.026316\n",
              "\n",
              "[452 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np1ydmhGDPC8"
      },
      "source": [
        "# create 20 days simple moving average column\n",
        "pd_price['20_SMA'] = pd_price['Close'].rolling(window = 20, min_periods = 1).mean()\n",
        "pd_price['50_SMA'] = pd_price['Close'].rolling(window = 50, min_periods = 1).mean()"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XWoUEidDcNL"
      },
      "source": [
        "pd_price['20_EMA'] = round(pd_price['Close'].ewm(span = 20, adjust = False).mean(), 2)\n",
        "pd_price['50_EMA'] = round(pd_price['Close'].ewm(span = 50, adjust = False).mean(), 2)"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Z6XY5xvkEFsq",
        "outputId": "28e02495-e181-4ed5-f262-9ee99818f080"
      },
      "source": [
        "pd_price"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Change</th>\n",
              "      <th>20_SMA</th>\n",
              "      <th>50_SMA</th>\n",
              "      <th>20_EMA</th>\n",
              "      <th>50_EMA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>52400</td>\n",
              "      <td>52600</td>\n",
              "      <td>50000</td>\n",
              "      <td>50100</td>\n",
              "      <td>194505</td>\n",
              "      <td>-0.042065</td>\n",
              "      <td>50100.000000</td>\n",
              "      <td>50100.000000</td>\n",
              "      <td>50100.00</td>\n",
              "      <td>50100.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>50500</td>\n",
              "      <td>51300</td>\n",
              "      <td>50100</td>\n",
              "      <td>50800</td>\n",
              "      <td>246721</td>\n",
              "      <td>0.013972</td>\n",
              "      <td>50450.000000</td>\n",
              "      <td>50450.000000</td>\n",
              "      <td>50166.67</td>\n",
              "      <td>50127.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>50800</td>\n",
              "      <td>50800</td>\n",
              "      <td>49900</td>\n",
              "      <td>50200</td>\n",
              "      <td>142825</td>\n",
              "      <td>-0.011811</td>\n",
              "      <td>50366.666667</td>\n",
              "      <td>50366.666667</td>\n",
              "      <td>50169.84</td>\n",
              "      <td>50130.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-07</td>\n",
              "      <td>50500</td>\n",
              "      <td>50500</td>\n",
              "      <td>49450</td>\n",
              "      <td>49750</td>\n",
              "      <td>192139</td>\n",
              "      <td>-0.008964</td>\n",
              "      <td>50212.500000</td>\n",
              "      <td>50212.500000</td>\n",
              "      <td>50129.86</td>\n",
              "      <td>50115.38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-08</td>\n",
              "      <td>49250</td>\n",
              "      <td>49300</td>\n",
              "      <td>47950</td>\n",
              "      <td>48550</td>\n",
              "      <td>211203</td>\n",
              "      <td>-0.024121</td>\n",
              "      <td>49880.000000</td>\n",
              "      <td>49880.000000</td>\n",
              "      <td>49979.39</td>\n",
              "      <td>50053.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>2021-10-25</td>\n",
              "      <td>66000</td>\n",
              "      <td>66900</td>\n",
              "      <td>65600</td>\n",
              "      <td>66400</td>\n",
              "      <td>75686</td>\n",
              "      <td>0.004539</td>\n",
              "      <td>65025.000000</td>\n",
              "      <td>61806.000000</td>\n",
              "      <td>64848.80</td>\n",
              "      <td>62111.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>2021-10-26</td>\n",
              "      <td>67100</td>\n",
              "      <td>67100</td>\n",
              "      <td>65400</td>\n",
              "      <td>66000</td>\n",
              "      <td>82375</td>\n",
              "      <td>-0.006024</td>\n",
              "      <td>65190.000000</td>\n",
              "      <td>61970.000000</td>\n",
              "      <td>64958.43</td>\n",
              "      <td>62263.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>2021-10-27</td>\n",
              "      <td>65700</td>\n",
              "      <td>65900</td>\n",
              "      <td>64400</td>\n",
              "      <td>65300</td>\n",
              "      <td>116769</td>\n",
              "      <td>-0.010606</td>\n",
              "      <td>65325.000000</td>\n",
              "      <td>62134.000000</td>\n",
              "      <td>64990.96</td>\n",
              "      <td>62382.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>2021-10-28</td>\n",
              "      <td>64900</td>\n",
              "      <td>65000</td>\n",
              "      <td>60600</td>\n",
              "      <td>60800</td>\n",
              "      <td>282584</td>\n",
              "      <td>-0.068913</td>\n",
              "      <td>65120.000000</td>\n",
              "      <td>62184.000000</td>\n",
              "      <td>64591.82</td>\n",
              "      <td>62320.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>2021-10-29</td>\n",
              "      <td>60700</td>\n",
              "      <td>61500</td>\n",
              "      <td>58400</td>\n",
              "      <td>59200</td>\n",
              "      <td>302475</td>\n",
              "      <td>-0.026316</td>\n",
              "      <td>64965.000000</td>\n",
              "      <td>62208.000000</td>\n",
              "      <td>64078.32</td>\n",
              "      <td>62198.33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>452 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date   Open   High  ...        50_SMA    20_EMA    50_EMA\n",
              "0    2020-01-02  52400  52600  ...  50100.000000  50100.00  50100.00\n",
              "1    2020-01-03  50500  51300  ...  50450.000000  50166.67  50127.45\n",
              "2    2020-01-06  50800  50800  ...  50366.666667  50169.84  50130.30\n",
              "3    2020-01-07  50500  50500  ...  50212.500000  50129.86  50115.38\n",
              "4    2020-01-08  49250  49300  ...  49880.000000  49979.39  50053.99\n",
              "..          ...    ...    ...  ...           ...       ...       ...\n",
              "447  2021-10-25  66000  66900  ...  61806.000000  64848.80  62111.20\n",
              "448  2021-10-26  67100  67100  ...  61970.000000  64958.43  62263.70\n",
              "449  2021-10-27  65700  65900  ...  62134.000000  64990.96  62382.78\n",
              "450  2021-10-28  64900  65000  ...  62184.000000  64591.82  62320.71\n",
              "451  2021-10-29  60700  61500  ...  62208.000000  64078.32  62198.33\n",
              "\n",
              "[452 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "W3bjvx5rEH07",
        "outputId": "5297591c-839c-4b06-857c-493e2bae1ab6"
      },
      "source": [
        "pd_price.corr()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Change</th>\n",
              "      <th>20_SMA</th>\n",
              "      <th>50_SMA</th>\n",
              "      <th>20_EMA</th>\n",
              "      <th>50_EMA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Open</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994792</td>\n",
              "      <td>0.995971</td>\n",
              "      <td>0.990030</td>\n",
              "      <td>-0.487829</td>\n",
              "      <td>-0.046606</td>\n",
              "      <td>0.941300</td>\n",
              "      <td>0.842325</td>\n",
              "      <td>0.960179</td>\n",
              "      <td>0.897233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>High</th>\n",
              "      <td>0.994792</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.994160</td>\n",
              "      <td>0.995576</td>\n",
              "      <td>-0.458572</td>\n",
              "      <td>0.020093</td>\n",
              "      <td>0.938323</td>\n",
              "      <td>0.842136</td>\n",
              "      <td>0.957781</td>\n",
              "      <td>0.896339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Low</th>\n",
              "      <td>0.995971</td>\n",
              "      <td>0.994160</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.995834</td>\n",
              "      <td>-0.511856</td>\n",
              "      <td>0.007130</td>\n",
              "      <td>0.939727</td>\n",
              "      <td>0.840776</td>\n",
              "      <td>0.959067</td>\n",
              "      <td>0.894939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Close</th>\n",
              "      <td>0.990030</td>\n",
              "      <td>0.995576</td>\n",
              "      <td>0.995834</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.485917</td>\n",
              "      <td>0.073626</td>\n",
              "      <td>0.934374</td>\n",
              "      <td>0.836900</td>\n",
              "      <td>0.954169</td>\n",
              "      <td>0.890590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Volume</th>\n",
              "      <td>-0.487829</td>\n",
              "      <td>-0.458572</td>\n",
              "      <td>-0.511856</td>\n",
              "      <td>-0.485917</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.050780</td>\n",
              "      <td>-0.454384</td>\n",
              "      <td>-0.405544</td>\n",
              "      <td>-0.466941</td>\n",
              "      <td>-0.416713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Change</th>\n",
              "      <td>-0.046606</td>\n",
              "      <td>0.020093</td>\n",
              "      <td>0.007130</td>\n",
              "      <td>0.073626</td>\n",
              "      <td>0.050780</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.071877</td>\n",
              "      <td>-0.069756</td>\n",
              "      <td>-0.063835</td>\n",
              "      <td>-0.074470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_SMA</th>\n",
              "      <td>0.941300</td>\n",
              "      <td>0.938323</td>\n",
              "      <td>0.939727</td>\n",
              "      <td>0.934374</td>\n",
              "      <td>-0.454384</td>\n",
              "      <td>-0.071877</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.932991</td>\n",
              "      <td>0.996159</td>\n",
              "      <td>0.972104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50_SMA</th>\n",
              "      <td>0.842325</td>\n",
              "      <td>0.842136</td>\n",
              "      <td>0.840776</td>\n",
              "      <td>0.836900</td>\n",
              "      <td>-0.405544</td>\n",
              "      <td>-0.069756</td>\n",
              "      <td>0.932991</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.935392</td>\n",
              "      <td>0.984858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_EMA</th>\n",
              "      <td>0.960179</td>\n",
              "      <td>0.957781</td>\n",
              "      <td>0.959067</td>\n",
              "      <td>0.954169</td>\n",
              "      <td>-0.466941</td>\n",
              "      <td>-0.063835</td>\n",
              "      <td>0.996159</td>\n",
              "      <td>0.935392</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.974114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50_EMA</th>\n",
              "      <td>0.897233</td>\n",
              "      <td>0.896339</td>\n",
              "      <td>0.894939</td>\n",
              "      <td>0.890590</td>\n",
              "      <td>-0.416713</td>\n",
              "      <td>-0.074470</td>\n",
              "      <td>0.972104</td>\n",
              "      <td>0.984858</td>\n",
              "      <td>0.974114</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Open      High       Low  ...    50_SMA    20_EMA    50_EMA\n",
              "Open    1.000000  0.994792  0.995971  ...  0.842325  0.960179  0.897233\n",
              "High    0.994792  1.000000  0.994160  ...  0.842136  0.957781  0.896339\n",
              "Low     0.995971  0.994160  1.000000  ...  0.840776  0.959067  0.894939\n",
              "Close   0.990030  0.995576  0.995834  ...  0.836900  0.954169  0.890590\n",
              "Volume -0.487829 -0.458572 -0.511856  ... -0.405544 -0.466941 -0.416713\n",
              "Change -0.046606  0.020093  0.007130  ... -0.069756 -0.063835 -0.074470\n",
              "20_SMA  0.941300  0.938323  0.939727  ...  0.932991  0.996159  0.972104\n",
              "50_SMA  0.842325  0.842136  0.840776  ...  1.000000  0.935392  0.984858\n",
              "20_EMA  0.960179  0.957781  0.959067  ...  0.935392  1.000000  0.974114\n",
              "50_EMA  0.897233  0.896339  0.894939  ...  0.984858  0.974114  1.000000\n",
              "\n",
              "[10 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4DChqkYEX-t"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyDdgNJlKBhO",
        "outputId": "fd480088-de04-4418-d9d1-2a5a39fcbf1c"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "scale_cols = ['Open', 'High', 'Low', 'Close', 'Volume', '20_SMA', '50_EMA', '20_EMA', '50_EMA']\n",
        "df_scaled = scaler.fit_transform(pd_price[scale_cols])\n",
        "\n",
        "pd_scaled_price = pd.DataFrame(df_scaled)\n",
        "pd_scaled_price.columns = scale_cols\n",
        "\n",
        "print(pd_scaled_price)\n",
        "\n",
        "pd_sel_price = pd_price[scale_cols]"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Open      High       Low  ...    50_EMA    20_EMA    50_EMA\n",
            "0    0.653710  0.616867  0.621302  ...  0.512864  0.535152  0.512864\n",
            "1    0.608952  0.585542  0.623669  ...  0.513953  0.537233  0.513953\n",
            "2    0.616019  0.573494  0.618935  ...  0.514066  0.537332  0.514066\n",
            "3    0.608952  0.566265  0.608284  ...  0.513474  0.536084  0.513474\n",
            "4    0.579505  0.537349  0.572781  ...  0.511039  0.531387  0.511039\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "447  0.974087  0.961446  0.990533  ...  0.989229  0.995562  0.989229\n",
            "448  1.000000  0.966265  0.985799  ...  0.995277  0.998985  0.995277\n",
            "449  0.967020  0.937349  0.962130  ...  1.000000  1.000000  1.000000\n",
            "450  0.948174  0.915663  0.872189  ...  0.997538  0.987540  0.997538\n",
            "451  0.849234  0.831325  0.820118  ...  0.992685  0.971510  0.992685\n",
            "\n",
            "[452 rows x 9 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eZwDvNWK4xY",
        "outputId": "153116ab-6e3c-426d-9096-fe09e47db090"
      },
      "source": [
        "pd_scaled_price.shape"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(452, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dFPqZ1-K_ex"
      },
      "source": [
        "def make_dataset(data, label, window_size=20):\n",
        "    feature_list = []\n",
        "    label_list = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        feature_list.append(np.array(data.iloc[i:i+window_size]))\n",
        "        label_list.append(np.array(label.iloc[i+window_size]))\n",
        "    return np.array(feature_list), np.array(label_list)\n"
      ],
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyPJhA3AK1fn"
      },
      "source": [
        "TEST_SIZE = 350"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt34q9tFKp1Z"
      },
      "source": [
        "#train = pd_scaled_price[:TEST_SIZE]\n",
        "#test = pd_scaled_price[TEST_SIZE:]\n",
        "train = pd_sel_price[:TEST_SIZE]\n",
        "test = pd_sel_price[TEST_SIZE:]"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTRbJxR5K__F",
        "outputId": "c98bfbda-8065-4a0e-f313-3fd633459772"
      },
      "source": [
        "feature_cols = ['Open', 'High', 'Low', 'Volume', '20_SMA', '50_EMA', '20_EMA', '50_EMA']\n",
        "label_cols = ['Close']\n",
        "\n",
        "train_feature = train[feature_cols]\n",
        "train_label = train[label_cols]\n",
        "\n",
        "# train dataset\n",
        "train_feature, train_label = make_dataset(train_feature, train_label, 20)\n",
        "\n",
        "# train, validation set 생성\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(train_feature, train_label, test_size=0.2)\n",
        "\n",
        "print(x_train.shape, x_valid.shape)\n",
        "# ((6086, 20, 4), (1522, 20, 4))\n",
        "\n",
        "test_feature = test[feature_cols]\n",
        "test_label = test[label_cols]\n",
        "\n",
        "# test dataset (실제 예측 해볼 데이터)\n",
        "test_feature, test_label = make_dataset(test_feature, test_label, 20)\n",
        "\n",
        "print(test_feature.shape, test_label.shape)\n",
        "# ((180, 20, 4), (180, 1))"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(264, 20, 10) (66, 20, 10)\n",
            "(82, 20, 10) (82, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBLtiaNXLNCw"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.layers import LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(20, \n",
        "               input_shape=(train_feature.shape[1], train_feature.shape[2]), \n",
        "               activation='relu', \n",
        "               return_sequences=False)\n",
        "          )\n",
        "model.add(Dense(10))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OBzOEktDM9Lj",
        "outputId": "56761a64-43b3-4b58-a02a-e2abbe17c66c"
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "#early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
        "filename = os.path.join('result/', 'tmp_checkpoint.h5')\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=200, \n",
        "                    batch_size=16,\n",
        "                    validation_data=(x_valid, y_valid), \n",
        "                    callbacks=[checkpoint])\n",
        "'''\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=200, \n",
        "                    batch_size=16,\n",
        "                    validation_data=(x_valid, y_valid), \n",
        "                    callbacks=[early_stop, checkpoint])\n",
        "'''"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 171668224.0000\n",
            "Epoch 00001: val_loss improved from inf to 239158192.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 2s 25ms/step - loss: 156711888.0000 - val_loss: 239158192.0000\n",
            "Epoch 2/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 169742416.0000\n",
            "Epoch 00002: val_loss improved from 239158192.00000 to 238755664.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 155990144.0000 - val_loss: 238755664.0000\n",
            "Epoch 3/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 171763888.0000\n",
            "Epoch 00003: val_loss did not improve from 238755664.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 155217216.0000 - val_loss: 240575440.0000\n",
            "Epoch 4/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 153021744.0000\n",
            "Epoch 00004: val_loss improved from 238755664.00000 to 238724384.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 154282496.0000 - val_loss: 238724384.0000\n",
            "Epoch 5/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 150750704.0000\n",
            "Epoch 00005: val_loss improved from 238724384.00000 to 238457552.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 154183264.0000 - val_loss: 238457552.0000\n",
            "Epoch 6/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 129962928.0000\n",
            "Epoch 00006: val_loss improved from 238457552.00000 to 238021216.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 153414160.0000 - val_loss: 238021216.0000\n",
            "Epoch 7/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 142335776.0000\n",
            "Epoch 00007: val_loss did not improve from 238021216.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 153815808.0000 - val_loss: 240133456.0000\n",
            "Epoch 8/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 159576560.0000\n",
            "Epoch 00008: val_loss improved from 238021216.00000 to 237618112.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 153499872.0000 - val_loss: 237618112.0000\n",
            "Epoch 9/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 139278256.0000\n",
            "Epoch 00009: val_loss did not improve from 237618112.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 152613264.0000 - val_loss: 237754400.0000\n",
            "Epoch 10/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 149296752.0000\n",
            "Epoch 00010: val_loss did not improve from 237618112.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 152519616.0000 - val_loss: 238461136.0000\n",
            "Epoch 11/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 154092160.0000\n",
            "Epoch 00011: val_loss did not improve from 237618112.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 152706432.0000 - val_loss: 237641360.0000\n",
            "Epoch 12/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 117141128.0000\n",
            "Epoch 00012: val_loss improved from 237618112.00000 to 237426800.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 152073584.0000 - val_loss: 237426800.0000\n",
            "Epoch 13/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 157203616.0000\n",
            "Epoch 00013: val_loss did not improve from 237426800.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 152506416.0000 - val_loss: 237453504.0000\n",
            "Epoch 14/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 159940096.0000\n",
            "Epoch 00014: val_loss did not improve from 237426800.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 152729776.0000 - val_loss: 237596400.0000\n",
            "Epoch 15/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 157424032.0000\n",
            "Epoch 00015: val_loss improved from 237426800.00000 to 236948800.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 152787312.0000 - val_loss: 236948800.0000\n",
            "Epoch 16/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 160380320.0000\n",
            "Epoch 00016: val_loss improved from 236948800.00000 to 236789456.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 152227376.0000 - val_loss: 236789456.0000\n",
            "Epoch 17/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 156029792.0000\n",
            "Epoch 00017: val_loss did not improve from 236789456.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 151824496.0000 - val_loss: 237007872.0000\n",
            "Epoch 18/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 149739008.0000\n",
            "Epoch 00018: val_loss improved from 236789456.00000 to 236724240.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 151847104.0000 - val_loss: 236724240.0000\n",
            "Epoch 19/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 156489280.0000\n",
            "Epoch 00019: val_loss did not improve from 236724240.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 150977696.0000 - val_loss: 237325088.0000\n",
            "Epoch 20/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 181693168.0000\n",
            "Epoch 00020: val_loss improved from 236724240.00000 to 110576248.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 160117872.0000 - val_loss: 110576248.0000\n",
            "Epoch 21/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 119871496.0000\n",
            "Epoch 00021: val_loss improved from 110576248.00000 to 71762280.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 111440584.0000 - val_loss: 71762280.0000\n",
            "Epoch 22/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 85902032.0000 \n",
            "Epoch 00022: val_loss improved from 71762280.00000 to 71699352.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 78622720.0000 - val_loss: 71699352.0000\n",
            "Epoch 23/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 61349476.0000\n",
            "Epoch 00023: val_loss improved from 71699352.00000 to 12911544.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 53979580.0000 - val_loss: 12911544.0000\n",
            "Epoch 24/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 9512500.0000\n",
            "Epoch 00024: val_loss improved from 12911544.00000 to 12410021.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 9844494.0000 - val_loss: 12410021.0000\n",
            "Epoch 25/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 9586579.0000\n",
            "Epoch 00025: val_loss did not improve from 12410021.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 11121800.0000 - val_loss: 13917941.0000\n",
            "Epoch 26/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 11428254.0000\n",
            "Epoch 00026: val_loss improved from 12410021.00000 to 11979181.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 10981641.0000 - val_loss: 11979181.0000\n",
            "Epoch 27/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 9805749.0000\n",
            "Epoch 00027: val_loss improved from 11979181.00000 to 11844854.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 10465204.0000 - val_loss: 11844854.0000\n",
            "Epoch 28/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 11204802.0000\n",
            "Epoch 00028: val_loss did not improve from 11844854.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 10732615.0000 - val_loss: 11961054.0000\n",
            "Epoch 29/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 10176179.0000\n",
            "Epoch 00029: val_loss improved from 11844854.00000 to 11748115.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 10192463.0000 - val_loss: 11748115.0000\n",
            "Epoch 30/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 10955749.0000\n",
            "Epoch 00030: val_loss improved from 11748115.00000 to 11360599.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 10479862.0000 - val_loss: 11360599.0000\n",
            "Epoch 31/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 9565603.0000\n",
            "Epoch 00031: val_loss did not improve from 11360599.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 10015263.0000 - val_loss: 11450981.0000\n",
            "Epoch 32/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 10051839.0000\n",
            "Epoch 00032: val_loss did not improve from 11360599.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9855260.0000 - val_loss: 11790612.0000\n",
            "Epoch 33/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 10506819.0000\n",
            "Epoch 00033: val_loss did not improve from 11360599.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 10093871.0000 - val_loss: 11363838.0000\n",
            "Epoch 34/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 9357348.0000\n",
            "Epoch 00034: val_loss improved from 11360599.00000 to 10987920.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 9773587.0000 - val_loss: 10987920.0000\n",
            "Epoch 35/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 9953694.0000 \n",
            "Epoch 00035: val_loss did not improve from 10987920.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 9837733.0000 - val_loss: 11271478.0000\n",
            "Epoch 36/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 10172422.0000\n",
            "Epoch 00036: val_loss improved from 10987920.00000 to 10870099.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 9548237.0000 - val_loss: 10870099.0000\n",
            "Epoch 37/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 9732771.0000\n",
            "Epoch 00037: val_loss did not improve from 10870099.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 9611470.0000 - val_loss: 10964769.0000\n",
            "Epoch 38/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 9980533.0000\n",
            "Epoch 00038: val_loss did not improve from 10870099.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9768640.0000 - val_loss: 11421282.0000\n",
            "Epoch 39/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8951887.0000\n",
            "Epoch 00039: val_loss improved from 10870099.00000 to 10686895.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 9922594.0000 - val_loss: 10686895.0000\n",
            "Epoch 40/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8528986.0000\n",
            "Epoch 00040: val_loss improved from 10686895.00000 to 10647717.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 9362631.0000 - val_loss: 10647717.0000\n",
            "Epoch 41/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 9522111.0000\n",
            "Epoch 00041: val_loss did not improve from 10647717.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9532764.0000 - val_loss: 10930969.0000\n",
            "Epoch 42/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 10901703.0000\n",
            "Epoch 00042: val_loss did not improve from 10647717.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 10003622.0000 - val_loss: 11197870.0000\n",
            "Epoch 43/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 9551295.0000 \n",
            "Epoch 00043: val_loss improved from 10647717.00000 to 10299417.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9660949.0000 - val_loss: 10299417.0000\n",
            "Epoch 44/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8179598.5000\n",
            "Epoch 00044: val_loss did not improve from 10299417.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9367820.0000 - val_loss: 10496487.0000\n",
            "Epoch 45/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 9389376.0000\n",
            "Epoch 00045: val_loss improved from 10299417.00000 to 10157646.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 9172600.0000 - val_loss: 10157646.0000\n",
            "Epoch 46/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8937479.0000\n",
            "Epoch 00046: val_loss did not improve from 10157646.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8926835.0000 - val_loss: 10180476.0000\n",
            "Epoch 47/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8830583.0000\n",
            "Epoch 00047: val_loss did not improve from 10157646.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 9059977.0000 - val_loss: 10245248.0000\n",
            "Epoch 48/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 9139957.0000\n",
            "Epoch 00048: val_loss did not improve from 10157646.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8903963.0000 - val_loss: 10232795.0000\n",
            "Epoch 49/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 8939961.0000\n",
            "Epoch 00049: val_loss improved from 10157646.00000 to 9880942.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8938857.0000 - val_loss: 9880942.0000\n",
            "Epoch 50/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 8371573.5000\n",
            "Epoch 00050: val_loss did not improve from 9880942.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 8722659.0000 - val_loss: 10021609.0000\n",
            "Epoch 51/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8876050.0000\n",
            "Epoch 00051: val_loss did not improve from 9880942.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 8722008.0000 - val_loss: 10111102.0000\n",
            "Epoch 52/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7885072.0000\n",
            "Epoch 00052: val_loss did not improve from 9880942.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 8563043.0000 - val_loss: 9900465.0000\n",
            "Epoch 53/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8637726.0000\n",
            "Epoch 00053: val_loss did not improve from 9880942.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 8740090.0000 - val_loss: 10083901.0000\n",
            "Epoch 54/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 8562722.0000\n",
            "Epoch 00054: val_loss did not improve from 9880942.00000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 8562722.0000 - val_loss: 9954347.0000\n",
            "Epoch 55/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8910814.0000\n",
            "Epoch 00055: val_loss did not improve from 9880942.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8439449.0000 - val_loss: 9911893.0000\n",
            "Epoch 56/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8405752.0000 \n",
            "Epoch 00056: val_loss did not improve from 9880942.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8432741.0000 - val_loss: 9901647.0000\n",
            "Epoch 57/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8438210.0000\n",
            "Epoch 00057: val_loss improved from 9880942.00000 to 9682270.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 8381311.0000 - val_loss: 9682270.0000\n",
            "Epoch 58/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8280210.5000\n",
            "Epoch 00058: val_loss did not improve from 9682270.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8360418.0000 - val_loss: 10165433.0000\n",
            "Epoch 59/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8483947.0000\n",
            "Epoch 00059: val_loss did not improve from 9682270.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8202286.5000 - val_loss: 9701436.0000\n",
            "Epoch 60/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8310534.5000\n",
            "Epoch 00060: val_loss improved from 9682270.00000 to 9574575.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 8280481.0000 - val_loss: 9574575.0000\n",
            "Epoch 61/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7646834.0000\n",
            "Epoch 00061: val_loss did not improve from 9574575.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8150024.0000 - val_loss: 9702203.0000\n",
            "Epoch 62/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7960629.0000\n",
            "Epoch 00062: val_loss improved from 9574575.00000 to 9546117.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 8196878.5000 - val_loss: 9546117.0000\n",
            "Epoch 63/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7694519.5000\n",
            "Epoch 00063: val_loss did not improve from 9546117.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7963512.0000 - val_loss: 9821906.0000\n",
            "Epoch 64/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7796815.0000\n",
            "Epoch 00064: val_loss did not improve from 9546117.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8207959.5000 - val_loss: 9717287.0000\n",
            "Epoch 65/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 7667474.0000\n",
            "Epoch 00065: val_loss did not improve from 9546117.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 8246823.0000 - val_loss: 9810056.0000\n",
            "Epoch 66/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7918842.5000\n",
            "Epoch 00066: val_loss did not improve from 9546117.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8244888.0000 - val_loss: 9815852.0000\n",
            "Epoch 67/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7654953.5000\n",
            "Epoch 00067: val_loss did not improve from 9546117.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 7837546.5000 - val_loss: 9549471.0000\n",
            "Epoch 68/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8394999.0000 \n",
            "Epoch 00068: val_loss improved from 9546117.00000 to 9404063.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 8611863.0000 - val_loss: 9404063.0000\n",
            "Epoch 69/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7383377.0000\n",
            "Epoch 00069: val_loss did not improve from 9404063.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7919163.0000 - val_loss: 9453001.0000\n",
            "Epoch 70/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 6690898.5000\n",
            "Epoch 00070: val_loss did not improve from 9404063.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7948474.5000 - val_loss: 9484561.0000\n",
            "Epoch 71/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8056650.5000\n",
            "Epoch 00071: val_loss improved from 9404063.00000 to 9310891.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 7728977.0000 - val_loss: 9310891.0000\n",
            "Epoch 72/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8624176.0000\n",
            "Epoch 00072: val_loss did not improve from 9310891.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8587811.0000 - val_loss: 10271918.0000\n",
            "Epoch 73/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 8772534.0000\n",
            "Epoch 00073: val_loss did not improve from 9310891.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 8558080.0000 - val_loss: 10039567.0000\n",
            "Epoch 74/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 7447923.0000\n",
            "Epoch 00074: val_loss did not improve from 9310891.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 8047147.0000 - val_loss: 9820704.0000\n",
            "Epoch 75/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 9021322.0000\n",
            "Epoch 00075: val_loss did not improve from 9310891.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 8355245.5000 - val_loss: 9748775.0000\n",
            "Epoch 76/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 8886012.0000\n",
            "Epoch 00076: val_loss improved from 9310891.00000 to 9165583.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 8645316.0000 - val_loss: 9165583.0000\n",
            "Epoch 77/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 7819512.5000\n",
            "Epoch 00077: val_loss did not improve from 9165583.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7533103.0000 - val_loss: 9270638.0000\n",
            "Epoch 78/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 7467723.0000\n",
            "Epoch 00078: val_loss did not improve from 9165583.00000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 7467723.0000 - val_loss: 10110415.0000\n",
            "Epoch 79/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7665291.0000\n",
            "Epoch 00079: val_loss improved from 9165583.00000 to 9089605.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 7699625.5000 - val_loss: 9089605.0000\n",
            "Epoch 80/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7338985.5000\n",
            "Epoch 00080: val_loss did not improve from 9089605.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 7584787.0000 - val_loss: 9110273.0000\n",
            "Epoch 81/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 7386213.5000\n",
            "Epoch 00081: val_loss did not improve from 9089605.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7386213.5000 - val_loss: 9644548.0000\n",
            "Epoch 82/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 7562209.5000\n",
            "Epoch 00082: val_loss did not improve from 9089605.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7367298.5000 - val_loss: 9117790.0000\n",
            "Epoch 83/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 8225994.0000\n",
            "Epoch 00083: val_loss did not improve from 9089605.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7440757.5000 - val_loss: 9310376.0000\n",
            "Epoch 84/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 6732270.5000\n",
            "Epoch 00084: val_loss improved from 9089605.00000 to 8870660.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 7432996.5000 - val_loss: 8870660.0000\n",
            "Epoch 85/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7952257.0000\n",
            "Epoch 00085: val_loss did not improve from 8870660.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 7383340.5000 - val_loss: 9662372.0000\n",
            "Epoch 86/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7208104.0000\n",
            "Epoch 00086: val_loss did not improve from 8870660.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7200853.5000 - val_loss: 8960169.0000\n",
            "Epoch 87/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7304332.0000\n",
            "Epoch 00087: val_loss did not improve from 8870660.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 7332246.5000 - val_loss: 9516680.0000\n",
            "Epoch 88/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7839311.0000\n",
            "Epoch 00088: val_loss improved from 8870660.00000 to 8839628.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7254670.5000 - val_loss: 8839628.0000\n",
            "Epoch 89/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 5993958.5000\n",
            "Epoch 00089: val_loss did not improve from 8839628.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7095485.5000 - val_loss: 9382908.0000\n",
            "Epoch 90/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 7463859.5000\n",
            "Epoch 00090: val_loss did not improve from 8839628.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 7442568.0000 - val_loss: 9485154.0000\n",
            "Epoch 91/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 7179169.0000\n",
            "Epoch 00091: val_loss did not improve from 8839628.00000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 7179169.0000 - val_loss: 9076608.0000\n",
            "Epoch 92/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7185144.0000\n",
            "Epoch 00092: val_loss improved from 8839628.00000 to 8807393.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7104096.0000 - val_loss: 8807393.0000\n",
            "Epoch 93/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7295628.5000\n",
            "Epoch 00093: val_loss improved from 8807393.00000 to 8713499.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 7043591.0000 - val_loss: 8713499.0000\n",
            "Epoch 94/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7221659.0000\n",
            "Epoch 00094: val_loss did not improve from 8713499.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7270243.0000 - val_loss: 8734139.0000\n",
            "Epoch 95/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 7086231.5000\n",
            "Epoch 00095: val_loss improved from 8713499.00000 to 8698462.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 7086231.5000 - val_loss: 8698462.0000\n",
            "Epoch 96/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6592986.0000\n",
            "Epoch 00096: val_loss improved from 8698462.00000 to 8547609.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 7031960.0000 - val_loss: 8547609.0000\n",
            "Epoch 97/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7029193.5000\n",
            "Epoch 00097: val_loss did not improve from 8547609.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 6963717.5000 - val_loss: 8660897.0000\n",
            "Epoch 98/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6085234.5000\n",
            "Epoch 00098: val_loss did not improve from 8547609.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 7003554.5000 - val_loss: 8802981.0000\n",
            "Epoch 99/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 6632296.5000\n",
            "Epoch 00099: val_loss did not improve from 8547609.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 7197672.0000 - val_loss: 8674870.0000\n",
            "Epoch 100/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 6759412.5000\n",
            "Epoch 00100: val_loss did not improve from 8547609.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 6878477.0000 - val_loss: 8816031.0000\n",
            "Epoch 101/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 6853414.0000\n",
            "Epoch 00101: val_loss did not improve from 8547609.00000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 6853414.0000 - val_loss: 8734798.0000\n",
            "Epoch 102/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 6884505.5000\n",
            "Epoch 00102: val_loss improved from 8547609.00000 to 8509600.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 6787446.0000 - val_loss: 8509600.0000\n",
            "Epoch 103/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7001564.5000\n",
            "Epoch 00103: val_loss did not improve from 8509600.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 6854248.0000 - val_loss: 8518294.0000\n",
            "Epoch 104/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 6501237.0000\n",
            "Epoch 00104: val_loss improved from 8509600.00000 to 8420331.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 6723865.0000 - val_loss: 8420331.0000\n",
            "Epoch 105/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6644449.0000\n",
            "Epoch 00105: val_loss did not improve from 8420331.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 6667368.5000 - val_loss: 8619625.0000\n",
            "Epoch 106/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6510134.0000\n",
            "Epoch 00106: val_loss improved from 8420331.00000 to 8410868.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 6627677.0000 - val_loss: 8410868.0000\n",
            "Epoch 107/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 6517365.5000\n",
            "Epoch 00107: val_loss did not improve from 8410868.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 6439496.5000 - val_loss: 8674509.0000\n",
            "Epoch 108/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 6395052.5000\n",
            "Epoch 00108: val_loss improved from 8410868.00000 to 8104784.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 6544574.0000 - val_loss: 8104784.0000\n",
            "Epoch 109/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6609613.5000\n",
            "Epoch 00109: val_loss did not improve from 8104784.00000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 6851001.5000 - val_loss: 8540944.0000\n",
            "Epoch 110/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6926135.0000\n",
            "Epoch 00110: val_loss did not improve from 8104784.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 6816463.5000 - val_loss: 8261539.0000\n",
            "Epoch 111/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 6362634.5000\n",
            "Epoch 00111: val_loss improved from 8104784.00000 to 7966470.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 6581304.0000 - val_loss: 7966470.5000\n",
            "Epoch 112/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6204706.5000\n",
            "Epoch 00112: val_loss did not improve from 7966470.50000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 6331645.5000 - val_loss: 8630369.0000\n",
            "Epoch 113/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 7033307.0000\n",
            "Epoch 00113: val_loss improved from 7966470.50000 to 7811639.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 6618358.5000 - val_loss: 7811639.0000\n",
            "Epoch 114/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 6574917.0000\n",
            "Epoch 00114: val_loss improved from 7811639.00000 to 7284389.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 6330216.5000 - val_loss: 7284389.5000\n",
            "Epoch 115/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 7123464.0000\n",
            "Epoch 00115: val_loss improved from 7284389.50000 to 6544408.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 6528535.0000 - val_loss: 6544408.5000\n",
            "Epoch 116/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 4909084.0000\n",
            "Epoch 00116: val_loss improved from 6544408.50000 to 6272909.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 5602248.5000 - val_loss: 6272909.5000\n",
            "Epoch 117/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 5319962.5000\n",
            "Epoch 00117: val_loss improved from 6272909.50000 to 5788792.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 5062129.5000 - val_loss: 5788792.0000\n",
            "Epoch 118/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 4831506.0000\n",
            "Epoch 00118: val_loss improved from 5788792.00000 to 5581513.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 5186730.0000 - val_loss: 5581513.5000\n",
            "Epoch 119/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 4356602.0000\n",
            "Epoch 00119: val_loss improved from 5581513.50000 to 5356535.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 4776878.5000 - val_loss: 5356535.5000\n",
            "Epoch 120/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 5011848.0000\n",
            "Epoch 00120: val_loss improved from 5356535.50000 to 4951346.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 4723959.5000 - val_loss: 4951346.5000\n",
            "Epoch 121/200\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 4516299.5000\n",
            "Epoch 00121: val_loss did not improve from 4951346.50000\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 4494598.0000 - val_loss: 5540927.0000\n",
            "Epoch 122/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 4250995.5000\n",
            "Epoch 00122: val_loss did not improve from 4951346.50000\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 4183796.0000 - val_loss: 5076772.0000\n",
            "Epoch 123/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 4400314.5000\n",
            "Epoch 00123: val_loss did not improve from 4951346.50000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 4108836.7500 - val_loss: 5381802.0000\n",
            "Epoch 124/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 4274387.5000\n",
            "Epoch 00124: val_loss improved from 4951346.50000 to 4183207.25000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 4415301.0000 - val_loss: 4183207.2500\n",
            "Epoch 125/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 4047548.2500\n",
            "Epoch 00125: val_loss did not improve from 4183207.25000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 4047548.2500 - val_loss: 4301999.0000\n",
            "Epoch 126/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 3494970.2500\n",
            "Epoch 00126: val_loss improved from 4183207.25000 to 4026395.25000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 3588178.0000 - val_loss: 4026395.2500\n",
            "Epoch 127/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 3559361.5000\n",
            "Epoch 00127: val_loss improved from 4026395.25000 to 3712885.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 3389350.0000 - val_loss: 3712885.0000\n",
            "Epoch 128/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 3271345.7500\n",
            "Epoch 00128: val_loss did not improve from 3712885.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 3350966.7500 - val_loss: 4175372.0000\n",
            "Epoch 129/200\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 3571458.2500\n",
            "Epoch 00129: val_loss improved from 3712885.00000 to 3700394.25000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 3597924.0000 - val_loss: 3700394.2500\n",
            "Epoch 130/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2854896.2500\n",
            "Epoch 00130: val_loss improved from 3700394.25000 to 3286038.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 3105181.5000 - val_loss: 3286038.0000\n",
            "Epoch 131/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 3449637.5000\n",
            "Epoch 00131: val_loss improved from 3286038.00000 to 3274645.75000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 3371861.7500 - val_loss: 3274645.7500\n",
            "Epoch 132/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 3313801.0000\n",
            "Epoch 00132: val_loss improved from 3274645.75000 to 3200329.75000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 3531371.2500 - val_loss: 3200329.7500\n",
            "Epoch 133/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 2679357.7500\n",
            "Epoch 00133: val_loss improved from 3200329.75000 to 3013436.25000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2780736.0000 - val_loss: 3013436.2500\n",
            "Epoch 134/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 3108214.7500\n",
            "Epoch 00134: val_loss did not improve from 3013436.25000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 3483519.7500 - val_loss: 3910850.0000\n",
            "Epoch 135/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2992789.0000\n",
            "Epoch 00135: val_loss did not improve from 3013436.25000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 3291263.5000 - val_loss: 3038980.5000\n",
            "Epoch 136/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2693515.5000\n",
            "Epoch 00136: val_loss improved from 3013436.25000 to 2788531.25000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2582980.0000 - val_loss: 2788531.2500\n",
            "Epoch 137/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2733820.5000\n",
            "Epoch 00137: val_loss improved from 2788531.25000 to 2687843.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2685685.7500 - val_loss: 2687843.0000\n",
            "Epoch 138/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2564470.0000\n",
            "Epoch 00138: val_loss improved from 2687843.00000 to 2649019.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2602650.2500 - val_loss: 2649019.5000\n",
            "Epoch 139/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2650719.2500\n",
            "Epoch 00139: val_loss did not improve from 2649019.50000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2624170.7500 - val_loss: 3105602.0000\n",
            "Epoch 140/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2446782.7500\n",
            "Epoch 00140: val_loss did not improve from 2649019.50000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2411918.5000 - val_loss: 2961478.5000\n",
            "Epoch 141/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 2529918.7500\n",
            "Epoch 00141: val_loss improved from 2649019.50000 to 2465328.25000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2502326.7500 - val_loss: 2465328.2500\n",
            "Epoch 142/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2108140.7500\n",
            "Epoch 00142: val_loss did not improve from 2465328.25000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2334442.2500 - val_loss: 3206472.2500\n",
            "Epoch 143/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 3050055.2500\n",
            "Epoch 00143: val_loss did not improve from 2465328.25000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2861084.2500 - val_loss: 2484260.0000\n",
            "Epoch 144/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2294308.7500\n",
            "Epoch 00144: val_loss improved from 2465328.25000 to 2438882.75000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2352826.5000 - val_loss: 2438882.7500\n",
            "Epoch 145/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2171537.0000\n",
            "Epoch 00145: val_loss did not improve from 2438882.75000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2354356.7500 - val_loss: 3358455.7500\n",
            "Epoch 146/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2324098.7500\n",
            "Epoch 00146: val_loss improved from 2438882.75000 to 2245107.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2266522.2500 - val_loss: 2245107.5000\n",
            "Epoch 147/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1846220.6250\n",
            "Epoch 00147: val_loss did not improve from 2245107.50000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2095997.8750 - val_loss: 2902804.5000\n",
            "Epoch 148/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 3065491.7500\n",
            "Epoch 00148: val_loss did not improve from 2245107.50000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2795280.2500 - val_loss: 2371569.0000\n",
            "Epoch 149/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2114165.5000\n",
            "Epoch 00149: val_loss improved from 2245107.50000 to 2220468.50000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2099757.0000 - val_loss: 2220468.5000\n",
            "Epoch 150/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 2042338.3750\n",
            "Epoch 00150: val_loss did not improve from 2220468.50000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2042338.3750 - val_loss: 3396068.0000\n",
            "Epoch 151/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2581565.2500\n",
            "Epoch 00151: val_loss improved from 2220468.50000 to 2125636.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2677823.2500 - val_loss: 2125636.0000\n",
            "Epoch 152/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2101497.7500\n",
            "Epoch 00152: val_loss did not improve from 2125636.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2257698.7500 - val_loss: 2138988.7500\n",
            "Epoch 153/200\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 2159698.0000\n",
            "Epoch 00153: val_loss did not improve from 2125636.00000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2121027.0000 - val_loss: 3923946.7500\n",
            "Epoch 154/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2074760.2500\n",
            "Epoch 00154: val_loss did not improve from 2125636.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2162643.5000 - val_loss: 2146651.7500\n",
            "Epoch 155/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1931406.6250\n",
            "Epoch 00155: val_loss improved from 2125636.00000 to 2073394.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1909189.7500 - val_loss: 2073394.0000\n",
            "Epoch 156/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 1841647.2500\n",
            "Epoch 00156: val_loss did not improve from 2073394.00000\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1909898.0000 - val_loss: 2078628.6250\n",
            "Epoch 157/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 1928046.2500\n",
            "Epoch 00157: val_loss did not improve from 2073394.00000\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1928046.2500 - val_loss: 2075810.1250\n",
            "Epoch 158/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2198647.2500\n",
            "Epoch 00158: val_loss improved from 2073394.00000 to 2063230.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2062945.7500 - val_loss: 2063230.0000\n",
            "Epoch 159/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1878746.0000\n",
            "Epoch 00159: val_loss did not improve from 2063230.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1983538.7500 - val_loss: 2215118.2500\n",
            "Epoch 160/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2112434.2500\n",
            "Epoch 00160: val_loss improved from 2063230.00000 to 1981622.00000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 2058281.2500 - val_loss: 1981622.0000\n",
            "Epoch 161/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2204473.2500\n",
            "Epoch 00161: val_loss did not improve from 1981622.00000\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2142956.0000 - val_loss: 2166394.5000\n",
            "Epoch 162/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1973992.0000\n",
            "Epoch 00162: val_loss improved from 1981622.00000 to 1958179.37500, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2035718.5000 - val_loss: 1958179.3750\n",
            "Epoch 163/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1902893.8750\n",
            "Epoch 00163: val_loss did not improve from 1958179.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1871557.5000 - val_loss: 2459202.0000\n",
            "Epoch 164/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1746740.6250\n",
            "Epoch 00164: val_loss improved from 1958179.37500 to 1939314.37500, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1852198.3750 - val_loss: 1939314.3750\n",
            "Epoch 165/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 1903804.0000\n",
            "Epoch 00165: val_loss did not improve from 1939314.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1896504.1250 - val_loss: 2001240.1250\n",
            "Epoch 166/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2088592.0000\n",
            "Epoch 00166: val_loss did not improve from 1939314.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2211965.5000 - val_loss: 2556278.2500\n",
            "Epoch 167/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 1733495.5000\n",
            "Epoch 00167: val_loss did not improve from 1939314.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1805682.8750 - val_loss: 1947757.1250\n",
            "Epoch 168/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 1633740.5000\n",
            "Epoch 00168: val_loss improved from 1939314.37500 to 1921729.37500, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1800926.2500 - val_loss: 1921729.3750\n",
            "Epoch 169/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2885771.5000\n",
            "Epoch 00169: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2956054.5000 - val_loss: 2726318.7500\n",
            "Epoch 170/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 3419239.0000\n",
            "Epoch 00170: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 3159044.0000 - val_loss: 2430640.0000\n",
            "Epoch 171/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 2299200.7500\n",
            "Epoch 00171: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2299200.7500 - val_loss: 2818418.5000\n",
            "Epoch 172/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2115309.2500\n",
            "Epoch 00172: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2127200.5000 - val_loss: 2092526.2500\n",
            "Epoch 173/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2112251.7500\n",
            "Epoch 00173: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2041729.0000 - val_loss: 2583860.5000\n",
            "Epoch 174/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 1991107.2500\n",
            "Epoch 00174: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1991107.2500 - val_loss: 2111694.0000\n",
            "Epoch 175/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2031959.8750\n",
            "Epoch 00175: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1943879.3750 - val_loss: 2116307.7500\n",
            "Epoch 176/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 2126351.2500\n",
            "Epoch 00176: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 2126351.2500 - val_loss: 2117795.2500\n",
            "Epoch 177/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 1955626.0000\n",
            "Epoch 00177: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1966087.8750 - val_loss: 2233096.5000\n",
            "Epoch 178/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 1933696.3750\n",
            "Epoch 00178: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1933696.3750 - val_loss: 2902724.2500\n",
            "Epoch 179/200\n",
            "15/17 [=========================>....] - ETA: 0s - loss: 1943395.1250\n",
            "Epoch 00179: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 2032799.2500 - val_loss: 2132515.5000\n",
            "Epoch 180/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1899716.5000\n",
            "Epoch 00180: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1859134.7500 - val_loss: 2099808.0000\n",
            "Epoch 181/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 2115854.2500\n",
            "Epoch 00181: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2030540.0000 - val_loss: 2296156.0000\n",
            "Epoch 182/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 2063098.8750\n",
            "Epoch 00182: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 2027687.3750 - val_loss: 2062537.5000\n",
            "Epoch 183/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1872901.1250\n",
            "Epoch 00183: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1912936.3750 - val_loss: 2005340.2500\n",
            "Epoch 184/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 1853201.3750\n",
            "Epoch 00184: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1853201.3750 - val_loss: 2222259.0000\n",
            "Epoch 185/200\n",
            "14/17 [=======================>......] - ETA: 0s - loss: 1893557.1250\n",
            "Epoch 00185: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1882575.0000 - val_loss: 2693658.0000\n",
            "Epoch 186/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1923470.8750\n",
            "Epoch 00186: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1952005.6250 - val_loss: 2071447.2500\n",
            "Epoch 187/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1794513.2500\n",
            "Epoch 00187: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1894426.7500 - val_loss: 2039792.2500\n",
            "Epoch 188/200\n",
            "12/17 [====================>.........] - ETA: 0s - loss: 1899248.1250\n",
            "Epoch 00188: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1853690.2500 - val_loss: 1998815.3750\n",
            "Epoch 189/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1780918.0000\n",
            "Epoch 00189: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1821528.8750 - val_loss: 2614461.2500\n",
            "Epoch 190/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1884281.1250\n",
            "Epoch 00190: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1919458.3750 - val_loss: 1929422.8750\n",
            "Epoch 191/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1786937.3750\n",
            "Epoch 00191: val_loss did not improve from 1921729.37500\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 1932982.1250 - val_loss: 2452019.2500\n",
            "Epoch 192/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1734267.5000\n",
            "Epoch 00192: val_loss improved from 1921729.37500 to 1893923.87500, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1834062.0000 - val_loss: 1893923.8750\n",
            "Epoch 193/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1954452.6250\n",
            "Epoch 00193: val_loss did not improve from 1893923.87500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1896632.2500 - val_loss: 2850119.7500\n",
            "Epoch 194/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 2010620.3750\n",
            "Epoch 00194: val_loss did not improve from 1893923.87500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 2010620.3750 - val_loss: 2575291.7500\n",
            "Epoch 195/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1935699.7500\n",
            "Epoch 00195: val_loss did not improve from 1893923.87500\n",
            "17/17 [==============================] - 0s 11ms/step - loss: 1860471.8750 - val_loss: 1971981.8750\n",
            "Epoch 196/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 1786142.2500\n",
            "Epoch 00196: val_loss did not improve from 1893923.87500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1786142.2500 - val_loss: 2251072.0000\n",
            "Epoch 197/200\n",
            "17/17 [==============================] - ETA: 0s - loss: 1898618.3750\n",
            "Epoch 00197: val_loss did not improve from 1893923.87500\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1898618.3750 - val_loss: 2030807.6250\n",
            "Epoch 198/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1813701.1250\n",
            "Epoch 00198: val_loss improved from 1893923.87500 to 1873752.37500, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1856695.2500 - val_loss: 1873752.3750\n",
            "Epoch 199/200\n",
            "13/17 [=====================>........] - ETA: 0s - loss: 1874735.8750\n",
            "Epoch 00199: val_loss did not improve from 1873752.37500\n",
            "17/17 [==============================] - 0s 10ms/step - loss: 1842279.8750 - val_loss: 2217586.5000\n",
            "Epoch 200/200\n",
            "16/17 [===========================>..] - ETA: 0s - loss: 1764618.0000\n",
            "Epoch 00200: val_loss improved from 1873752.37500 to 1849564.25000, saving model to result/tmp_checkpoint.h5\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 1842828.0000 - val_loss: 1849564.2500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nhistory = model.fit(x_train, y_train,\\n                    epochs=200, \\n                    batch_size=16,\\n                    validation_data=(x_valid, y_valid), \\n                    callbacks=[early_stop, checkpoint])\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAzyZ66jNSyn"
      },
      "source": [
        "# weight 로딩\n",
        "model.load_weights(filename)\n",
        "\n",
        "# 예측\n",
        "pred = model.predict(test_feature)"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq_MDTV8Rw5h"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "2d2A4wUJNTlw",
        "outputId": "9afbde4e-016f-48dd-ec2d-63130a6e4638"
      },
      "source": [
        "plt.figure(figsize=(12, 9))\n",
        "plt.plot(test_label, label='actual')\n",
        "plt.plot(pred, label='prediction')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSrPoqawWZl4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}