{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TW3-P-mnY7Np"
   },
   "source": [
    "# Define Global Variable & Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:04.970406Z",
     "start_time": "2022-08-15T11:48:04.956444Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:27:41.323387Z",
     "iopub.status.busy": "2022-03-31T23:27:41.323063Z",
     "iopub.status.idle": "2022-03-31T23:27:41.358929Z",
     "shell.execute_reply": "2022-03-31T23:27:41.358235Z",
     "shell.execute_reply.started": "2022-03-31T23:27:41.323357Z"
    },
    "id": "GVxfOKf1Y6sp"
   },
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "SUBMISSION_PATH = './submit/'\n",
    "\n",
    "class ModelCfg:\n",
    "    epochs = 5\n",
    "    seed = 42\n",
    "    n_fold = 5\n",
    "    batch_size = 24\n",
    "\n",
    "    # 모델명 https://huggingface.co/models 참고\n",
    "    MODEL_NAME = 'seyonec/PubChem10M_SMILES_BPE_180k'\n",
    "    MAX_SEQ_LENGTH = 0\n",
    "    TOKENIZER = None\n",
    "    MODEL_PATH = './model/'\n",
    "    CLEAN_DATA_PATH = './cleaned/'\n",
    "    CONFIG_PATH = MODEL_PATH + 'model_config.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Lf6vcAlxmJE"
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:08.628084Z",
     "start_time": "2022-08-15T11:48:05.017132Z"
    },
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-03-31T23:27:52.149101Z",
     "iopub.status.busy": "2022-03-31T23:27:52.148365Z",
     "iopub.status.idle": "2022-03-31T23:27:58.782180Z",
     "shell.execute_reply": "2022-03-31T23:27:58.781453Z",
     "shell.execute_reply.started": "2022-03-31T23:27:52.149056Z"
    },
    "id": "A1tUc1OyYZJD",
    "outputId": "63c15a1f-600e-4617-a27e-7cf7378a87a7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-19 05:12:02.801127: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version :  1.11.0\n",
      "tokenizers version :  0.10.3\n",
      "transformers version :  4.15.0\n",
      "env: TOKENIZERS_PARALLELISM=true\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import dill\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from ast import literal_eval\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "import re\n",
    "import sys\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import joblib\n",
    "import itertools\n",
    "import platform\n",
    "import collections\n",
    "import scipy as sp\n",
    "import gc\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "from scipy.stats import gmean\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Parameter\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModel\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "\n",
    "print('torch version : ' , torch.__version__)\n",
    "print('tokenizers version : ', tokenizers.__version__)\n",
    "print('transformers version : ', transformers.__version__)\n",
    "%env TOKENIZERS_PARALLELISM=true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44LX2YVCgHnK"
   },
   "source": [
    "# Set Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:08.841764Z",
     "start_time": "2022-08-15T11:48:08.828921Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:27:59.466926Z",
     "iopub.status.busy": "2022-03-31T23:27:59.466399Z",
     "iopub.status.idle": "2022-03-31T23:27:59.475532Z",
     "shell.execute_reply": "2022-03-31T23:27:59.474661Z",
     "shell.execute_reply.started": "2022-03-31T23:27:59.466878Z"
    },
    "id": "jAM51XGqm2Ps"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(ModelCfg.MODEL_PATH):\n",
    "    print(f'create directory.....[{ModelCfg.MODEL_PATH}]')\n",
    "    os.mkdir(ModelCfg.MODEL_PATH)\n",
    "if not os.path.exists(ModelCfg.CLEAN_DATA_PATH): \n",
    "    print(f'create directory.....[{ModelCfg.CLEAN_DATA_PATH}]')\n",
    "    os.mkdir(ModelCfg.CLEAN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H59drnezxpkj"
   },
   "source": [
    "# Set Processor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:08.873713Z",
     "start_time": "2022-08-15T11:48:08.842877Z"
    },
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2022-03-31T23:27:59.477811Z",
     "iopub.status.busy": "2022-03-31T23:27:59.477251Z",
     "iopub.status.idle": "2022-03-31T23:27:59.523923Z",
     "shell.execute_reply": "2022-03-31T23:27:59.522947Z",
     "shell.execute_reply.started": "2022-03-31T23:27:59.477775Z"
    },
    "id": "ozL1fZOaYZJE",
    "outputId": "7cdaaa55-5a8e-404f-9f38-a0d0501ceee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device :  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device : ', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTrEE_DhxuE7"
   },
   "source": [
    "# User Define Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "458ni7b7wkCC"
   },
   "source": [
    "- Metric 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:08.889537Z",
     "start_time": "2022-08-15T11:48:08.874778Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:27:59.525767Z",
     "iopub.status.busy": "2022-03-31T23:27:59.525510Z",
     "iopub.status.idle": "2022-03-31T23:27:59.537874Z",
     "shell.execute_reply": "2022-03-31T23:27:59.537179Z",
     "shell.execute_reply.started": "2022-03-31T23:27:59.525732Z"
    },
    "id": "RM0ZDHZ3whRz"
   },
   "outputs": [],
   "source": [
    "def MY_RMSELoss(yhat, y):\n",
    "    return torch.sqrt(torch.mean((yhat-y)**2)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cS16vqqzMqa"
   },
   "source": [
    "- 재현성 구현 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:08.905341Z",
     "start_time": "2022-08-15T11:48:08.890536Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:27:59.564457Z",
     "iopub.status.busy": "2022-03-31T23:27:59.564034Z",
     "iopub.status.idle": "2022-03-31T23:27:59.575118Z",
     "shell.execute_reply": "2022-03-31T23:27:59.574378Z",
     "shell.execute_reply.started": "2022-03-31T23:27:59.564423Z"
    },
    "id": "cgvHm7wiYZJE"
   },
   "outputs": [],
   "source": [
    "def reset_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "reset_seeds(ModelCfg.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_vbobMBYZJF"
   },
   "source": [
    " # Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:08.952433Z",
     "start_time": "2022-08-15T11:48:08.906303Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:27:59.576760Z",
     "iopub.status.busy": "2022-03-31T23:27:59.576508Z",
     "iopub.status.idle": "2022-03-31T23:28:00.272158Z",
     "shell.execute_reply": "2022-03-31T23:28:00.271456Z",
     "shell.execute_reply.started": "2022-03-31T23:27:59.576726Z"
    },
    "id": "9l6cvSUCYZJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape:  (18157, 4)\n",
      "test.shape:  (457, 2)\n",
      "sample_submission.shape:  (457, 3)\n"
     ]
    }
   ],
   "source": [
    "def read_data_list():\n",
    "    train = pd.read_csv(f'{DATA_PATH}train_set.ReorgE.csv')\n",
    "    test = pd.read_csv(f'{DATA_PATH}test_set.csv')\n",
    "    sample_submission = pd.read_csv(f'{DATA_PATH}sample_submission.csv')\n",
    "    \n",
    "    print('train.shape: ', train.shape)\n",
    "    print('test.shape: ', test.shape)\n",
    "    print('sample_submission.shape: ', sample_submission.shape)\n",
    "\n",
    "    return train, test, sample_submission\n",
    "\n",
    "train, test, sample_submission = read_data_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ac1jVFcYZJJ"
   },
   "source": [
    "# Create Tokenizer Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:09.014555Z",
     "start_time": "2022-08-15T11:48:08.969387Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:04.912902Z",
     "iopub.status.busy": "2022-03-31T23:28:04.912681Z",
     "iopub.status.idle": "2022-03-31T23:28:13.262477Z",
     "shell.execute_reply": "2022-03-31T23:28:13.261694Z",
     "shell.execute_reply.started": "2022-03-31T23:28:04.912871Z"
    },
    "id": "ZSmK8miMYZJK",
    "outputId": "6331109f-7522-4660-f7d5-c80da1f5cdec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer object load & save......[seyonec/PubChem10M_SMILES_BPE_180k]\n",
      "{'input_ids': [0, 315, 21, 71, 263, 51, 13, 71, 22, 71, 12, 358, 22, 39, 13, 82, 12, 39, 13, 71, 21, 33, 51, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['Cn', '1', 'c', '(=', 'O', ')', 'c', '2', 'c', '(', 'ncn', '2', 'C', ')', 'n', '(', 'C', ')', 'c', '1', '=', 'O']\n"
     ]
    }
   ],
   "source": [
    "def make_tokenizer():\n",
    "    tokenizer = AutoTokenizer.from_pretrained(f'{ModelCfg.MODEL_NAME}', normalization=True, caeche_dir='./cache')\n",
    "    tokenizer.save_pretrained(f'{ModelCfg.MODEL_PATH}')\n",
    "    print(f'tokenizer object load & save......[{ModelCfg.MODEL_NAME}]')\n",
    "\n",
    "    example = \"Cn1c(=O)c2c(ncn2C)n(C)c1=O\"\n",
    "    tokens = tokenizer(example) # example\n",
    "    tokens_ = tokenizer.tokenize(example) # example\n",
    "    print(tokens)\n",
    "    print(tokens_)\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = make_tokenizer()\n",
    "ModelCfg.TOKENIZER = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UH9LbY44pzXp"
   },
   "source": [
    "# Preparing Dataset for Torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQDHroqDqHxC"
   },
   "source": [
    "- max_length 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.063607Z",
     "start_time": "2022-08-15T11:48:09.062217Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.292052Z",
     "iopub.status.busy": "2022-03-31T23:28:13.291704Z",
     "iopub.status.idle": "2022-03-31T23:28:13.306668Z",
     "shell.execute_reply": "2022-03-31T23:28:13.305840Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.292014Z"
    },
    "id": "nmj3M1T1qAtK",
    "outputId": "570b0963-83a8-4021-beb4-75c82a2310dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculate max sequence length....[seyonec/PubChem10M_SMILES_BPE_180k]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81d376838c8c4a79a6f68e42b71e82a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES max length :  200\n",
      "final max data length :  202\n"
     ]
    }
   ],
   "source": [
    "def cacl_max_lenth(train_data):\n",
    "    print(f'calculate max sequence length....[{ModelCfg.MODEL_NAME}]')\n",
    "    for text_col in ['SMILES']:\n",
    "        SMILES_lengths = []\n",
    "        text_values = tqdm(train[text_col].fillna('').values, total=len(train))\n",
    "        for text in text_values:\n",
    "            length = len(ModelCfg.TOKENIZER(text, add_special_tokens=False)['input_ids'])\n",
    "            SMILES_lengths.append(length)\n",
    "\n",
    "    max_seq_length = max(SMILES_lengths) + 2\n",
    "    print('SMILES max length : ', max(SMILES_lengths))\n",
    "    print('final max data length : ', max_seq_length)\n",
    "\n",
    "    return max_seq_length\n",
    "\n",
    "max_seq_length = cacl_max_lenth(train)\n",
    "ModelCfg.MAX_SEQ_LENGTH = max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JAmQv1Rq3j6"
   },
   "source": [
    "- Dataset 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.079493Z",
     "start_time": "2022-08-15T11:48:11.064572Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.308723Z",
     "iopub.status.busy": "2022-03-31T23:28:13.307917Z",
     "iopub.status.idle": "2022-03-31T23:28:13.329047Z",
     "shell.execute_reply": "2022-03-31T23:28:13.328112Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.308681Z"
    },
    "id": "z_DaTlO0qGGV"
   },
   "outputs": [],
   "source": [
    "def prepare_input(tokenizer, max_seq_length, smiles):\n",
    "    inputs = tokenizer(smiles, add_special_tokens=True, truncation=True, max_length=max_seq_length, padding=\"max_length\", return_offsets_mapping=False)\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "def create_label(Reorg_g, Reorg_ex):\n",
    "    return torch.tensor([Reorg_g, Reorg_ex], dtype=torch.float)\n",
    "\n",
    "class ChemiDataset(Dataset):\n",
    "    def __init__(self, cfg, df, is_train=False):\n",
    "        self.cfg = cfg\n",
    "        self.is_train = is_train\n",
    "        self.smiles = df['SMILES'].values\n",
    "        if not self.is_train:\n",
    "            self.Reorg_g = df['Reorg_g'].values\n",
    "            self.Reorg_ex = df['Reorg_ex'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg.TOKENIZER, self.cfg.MAX_SEQ_LENGTH, self.smiles[item])\n",
    "        label = np.array([])\n",
    "        if not self.is_train:\n",
    "            label = create_label(self.Reorg_g[item], self.Reorg_ex[item])\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.094978Z",
     "start_time": "2022-08-15T11:48:11.080466Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.330585Z",
     "iopub.status.busy": "2022-03-31T23:28:13.330267Z",
     "iopub.status.idle": "2022-03-31T23:28:13.411692Z",
     "shell.execute_reply": "2022-03-31T23:28:13.410938Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.330546Z"
    },
    "id": "-syWLopKvDrh",
    "outputId": "21cdb37e-6f59-499c-849b-9d26599da52f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs :  {'input_ids': tensor([[  0, 262,  63,  39,  36,  44,  65,  21, 373,  21,  39, 263,  51, 279,\n",
      "          39,  36,  36,  44, 336,  39,  13, 271, 263,  51,  13,  71,  21,  71,\n",
      "          12,  39,  13, 307,  12,  17,  82,  22, 276,  22,  13,  71,  21,  39,\n",
      "           7,  50,   2,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "labels :  torch.Size([1, 2]) tensor([[0.6315, 0.5351]])\n"
     ]
    }
   ],
   "source": [
    "# 1개 미리보기\n",
    "temp_train_dataset = ChemiDataset(ModelCfg, train)\n",
    "temp_train_loader = DataLoader(temp_train_dataset, batch_size=1, shuffle=False, drop_last=True)\n",
    "inputs, labels = next(iter(temp_train_loader))\n",
    "print('inputs : ', inputs)\n",
    "print('labels : ', labels.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.111045Z",
     "start_time": "2022-08-15T11:48:11.095948Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.413265Z",
     "iopub.status.busy": "2022-03-31T23:28:13.412863Z",
     "iopub.status.idle": "2022-03-31T23:28:13.444432Z",
     "shell.execute_reply": "2022-03-31T23:28:13.443660Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.413226Z"
    },
    "id": "31EdRcRcAqwm",
    "outputId": "7f8de338-0768-4cf2-e6be-c488625a590c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs :  {'input_ids': tensor([[  0, 265,  21,  ...,   1,   1,   1],\n",
      "        [  0, 262,  63,  ...,   1,   1,   1],\n",
      "        [  0, 265,  21,  ...,   1,   1,   1],\n",
      "        [  0,  51,  33,  ...,   1,   1,   1],\n",
      "        [  0, 265,  21,  ...,   1,   1,   1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "labels :  tensor([[0.5942, 1.0330],\n",
      "        [0.8123, 0.4900],\n",
      "        [0.2900, 0.3791],\n",
      "        [1.2005, 0.9994],\n",
      "        [0.8034, 0.6547]]) torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "# 5개 미리보기\n",
    "temp_train_dataset = ChemiDataset(ModelCfg, train)\n",
    "temp_train_loader = DataLoader(temp_train_dataset, batch_size=5, shuffle=True, drop_last=True)\n",
    "inputs, labels = next(iter(temp_train_loader))\n",
    "print('inputs : ', inputs)\n",
    "print('labels : ', labels, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvvHbWA3YZJN"
   },
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.157414Z",
     "start_time": "2022-08-15T11:48:11.143000Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.471110Z",
     "iopub.status.busy": "2022-03-31T23:28:13.470675Z",
     "iopub.status.idle": "2022-03-31T23:28:13.484293Z",
     "shell.execute_reply": "2022-03-31T23:28:13.483459Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.471072Z"
    },
    "id": "aidOcHC8YZJO"
   },
   "outputs": [],
   "source": [
    "class ChemoModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.MODEL_NAME, output_hidden_states=True)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.MODEL_NAME, config=self.config, cache_dir='./cache')\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "\n",
    "        self.fc_dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 2)\n",
    "\n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        return last_hidden_states\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(self.fc_dropout(feature))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.173078Z",
     "start_time": "2022-08-15T11:48:11.159051Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.485665Z",
     "iopub.status.busy": "2022-03-31T23:28:13.485363Z",
     "iopub.status.idle": "2022-03-31T23:28:13.497147Z",
     "shell.execute_reply": "2022-03-31T23:28:13.496472Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.485630Z"
    },
    "id": "xhNd0A8waYWe"
   },
   "outputs": [],
   "source": [
    "def get_optimizer_params(model):\n",
    "    no_decay = ['bias', 'LayerNorm.weight']\n",
    "    optimizer_parameters = [\n",
    "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "    return optimizer_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.188037Z",
     "start_time": "2022-08-15T11:48:11.178064Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.498654Z",
     "iopub.status.busy": "2022-03-31T23:28:13.498341Z",
     "iopub.status.idle": "2022-03-31T23:28:13.507740Z",
     "shell.execute_reply": "2022-03-31T23:28:13.507048Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.498619Z"
    },
    "id": "XYhgqG5Pa3VV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qihF4kNxYZJO"
   },
   "source": [
    "# Define Loss Class Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.203941Z",
     "start_time": "2022-08-15T11:48:11.189311Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.510962Z",
     "iopub.status.busy": "2022-03-31T23:28:13.510771Z",
     "iopub.status.idle": "2022-03-31T23:28:13.516982Z",
     "shell.execute_reply": "2022-03-31T23:28:13.516255Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.510932Z"
    },
    "id": "2JcekCOsbGgH"
   },
   "outputs": [],
   "source": [
    "class LoseMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wt8miOI3XzyT"
   },
   "source": [
    "# Define function for train & valid & inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.219315Z",
     "start_time": "2022-08-15T11:48:11.204939Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.518930Z",
     "iopub.status.busy": "2022-03-31T23:28:13.518417Z",
     "iopub.status.idle": "2022-03-31T23:28:13.540769Z",
     "shell.execute_reply": "2022-03-31T23:28:13.539970Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.518892Z"
    },
    "id": "xuW8Nj0TX5B3"
   },
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "    losses = LoseMeter()\n",
    "    epoch_display = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "    epoch_display.set_description(f'Epoch [{epoch+1}/{ModelCfg.epochs}]')\n",
    "    for step, (inputs, labels) in epoch_display:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        y_preds = model(inputs)\n",
    "        y_preds = y_preds[::, 0]\n",
    "        loss = criterion(y_preds, labels)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "        epoch_display.set_postfix(train_loss=losses.avg, lr=scheduler.get_lr()[0])\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    input_values = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs, _ in input_values:\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        y_preds = y_preds[::, 0]\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qokqKJFsZUl1"
   },
   "source": [
    "# Train Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:11.249389Z",
     "start_time": "2022-08-15T11:48:11.220854Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.542513Z",
     "iopub.status.busy": "2022-03-31T23:28:13.542108Z",
     "iopub.status.idle": "2022-03-31T23:28:13.566296Z",
     "shell.execute_reply": "2022-03-31T23:28:13.565629Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.542410Z"
    },
    "id": "6Qc3WKTPYZJO"
   },
   "outputs": [],
   "source": [
    "def train_loop(train):\n",
    "    # ====================================================\n",
    "    # data loader\n",
    "    # ====================================================\n",
    "    x_train_ = train.copy()\n",
    "    train_dataset = ChemiDataset(ModelCfg, x_train_)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=ModelCfg.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    # ====================================================\n",
    "    # model\n",
    "    # ====================================================\n",
    "    model = ChemoModel(ModelCfg, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, ModelCfg.MODEL_PATH + 'config.pth')\n",
    "    model.to(device)\n",
    "\n",
    "    # ====================================================\n",
    "    # optimizer\n",
    "    # ====================================================\n",
    "    optimizer_parameters = get_optimizer_params(model)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=2e-5, eps=1e-8, betas=(0.9, 0.999))\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    num_train_steps = int(len(x_train_) / ModelCfg.batch_size * ModelCfg.epochs)\n",
    "    scheduler = get_scheduler(ModelCfg, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = MY_RMSELoss\n",
    "    best_score = np.inf\n",
    "    for epoch in range(ModelCfg.epochs):\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_train_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # scoring\n",
    "        epoch_display = tqdm([0], leave=True)\n",
    "        for _ in epoch_display:\n",
    "            epoch_display.set_description(f'Epoch [{epoch+1}/{ModelCfg.epochs}]')\n",
    "\n",
    "            score = avg_train_loss\n",
    "            if best_score > score:\n",
    "                best_score = score\n",
    "                torch.save({'model': model.state_dict()}, f\"{ModelCfg.MODEL_PATH}{ModelCfg.MODEL_NAME.replace('/', '-')}_best.pth\")\n",
    "\n",
    "            elapsed = time.time() - start_time\n",
    "            epoch_display.set_postfix(avg_train_loss=f'{avg_train_loss:.4f}', time=f'{elapsed/60:.0f}m', Score=f'{score:.4f}')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFMLYZZZYZJO"
   },
   "source": [
    "# Training or Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:48:30.754164Z",
     "start_time": "2022-08-15T11:48:11.266442Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-31T23:28:13.568160Z",
     "iopub.status.busy": "2022-03-31T23:28:13.567710Z",
     "iopub.status.idle": "2022-04-01T06:24:27.155184Z",
     "shell.execute_reply": "2022-04-01T06:24:27.152687Z",
     "shell.execute_reply.started": "2022-03-31T23:28:13.568126Z"
    },
    "id": "XwxAu0DBYZJO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data.............\n",
      "train.shape:  (18157, 4)\n",
      "test.shape:  (457, 2)\n",
      "sample_submission.shape:  (457, 3)\n",
      "create tokenizer.............\n",
      "tokenizer object load & save......[seyonec/PubChem10M_SMILES_BPE_180k]\n",
      "{'input_ids': [0, 315, 21, 71, 263, 51, 13, 71, 22, 71, 12, 358, 22, 39, 13, 82, 12, 39, 13, 71, 21, 33, 51, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['Cn', '1', 'c', '(=', 'O', ')', 'c', '2', 'c', '(', 'ncn', '2', 'C', ')', 'n', '(', 'C', ')', 'c', '1', '=', 'O']\n",
      "calculate max sequence length.............\n",
      "calculate max sequence length....[seyonec/PubChem10M_SMILES_BPE_180k]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199c3c6bcae14204bcfeb1998d275e6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMILES max length :  200\n",
      "final max data length :  202\n",
      "TRAINING [seyonec/PubChem10M_SMILES_BPE_180k] MODEL.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/PubChem10M_SMILES_BPE_180k were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c1665f99a542aa88beb3eb4cc91fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c30fb682d946e7bf3dc2453c16f5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b0d10a34dc462ab01cd664a0eccef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1b1ebe80c1431f89d0f6b54e88f03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/756 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12160bb242e4f7a86213ef1555587e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFERENCE [seyonec/PubChem10M_SMILES_BPE_180k] MODEL.............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at seyonec/PubChem10M_SMILES_BPE_180k were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d18b334418429083f2ea7360e19fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seyonec/PubChem10M_SMILES_BPE_180k] predictions shape :  (457, 2)\n"
     ]
    }
   ],
   "source": [
    "# 데이타 읽기\n",
    "print('read data.............')\n",
    "train, test, sample_submission = read_data_list()\n",
    "\n",
    "# tokenizer 생성\n",
    "print('create tokenizer.............')\n",
    "tokenizer = make_tokenizer()\n",
    "ModelCfg.TOKENIZER = tokenizer\n",
    "\n",
    "# tokenizer에 입력하는 최대 길이 계산\n",
    "print('calculate max sequence length.............')\n",
    "max_seq_length = cacl_max_lenth(train)\n",
    "ModelCfg.MAX_SEQ_LENGTH = max_seq_length\n",
    "\n",
    "# 훈련\n",
    "print(f'TRAINING [{ModelCfg.MODEL_NAME}] MODEL.............')\n",
    "train_loop(train)\n",
    "\n",
    "# 예측\n",
    "print(f'INFERENCE [{ModelCfg.MODEL_NAME}] MODEL.............')\n",
    "test_dataset = ChemiDataset(ModelCfg, test, True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=ModelCfg.batch_size, shuffle=False, drop_last=False)\n",
    "model = ChemoModel(ModelCfg, config_path=None, pretrained=True)\n",
    "state = torch.load(f\"{ModelCfg.MODEL_PATH}{ModelCfg.MODEL_NAME.replace('/', '-')}_best.pth\", map_location=torch.device('cpu'))\n",
    "model.load_state_dict(state['model'])\n",
    "prediction = inference_fn(test_loader, model, device)\n",
    "del model, state\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(f'[{ModelCfg.MODEL_NAME}] predictions shape : ', np.array(prediction).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready for Submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-15T11:49:09.532312Z",
     "start_time": "2022-08-15T11:49:09.518766Z"
    },
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2022-04-01T06:24:27.175781Z",
     "iopub.status.idle": "2022-04-01T06:24:27.176729Z",
     "shell.execute_reply": "2022-04-01T06:24:27.176467Z",
     "shell.execute_reply.started": "2022-04-01T06:24:27.176439Z"
    },
    "id": "ZRoIejz7YZJP",
    "outputId": "64cd58bc-4f3f-46c7-fdb4-d63403c2a2fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'./Submission_Smiles.csv' saved complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Reorg_g</th>\n",
       "      <th>Reorg_ex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>0.352623</td>\n",
       "      <td>0.288610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>0.844584</td>\n",
       "      <td>0.639280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>0.557360</td>\n",
       "      <td>0.570624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>0.361972</td>\n",
       "      <td>0.412509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>0.332872</td>\n",
       "      <td>0.345510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>test_452</td>\n",
       "      <td>0.274158</td>\n",
       "      <td>0.291941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>test_453</td>\n",
       "      <td>0.192220</td>\n",
       "      <td>0.193173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>test_454</td>\n",
       "      <td>0.383139</td>\n",
       "      <td>0.368139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>test_455</td>\n",
       "      <td>0.384266</td>\n",
       "      <td>0.356970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>test_456</td>\n",
       "      <td>0.238958</td>\n",
       "      <td>0.230824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>457 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index   Reorg_g  Reorg_ex\n",
       "0      test_0  0.352623  0.288610\n",
       "1      test_1  0.844584  0.639280\n",
       "2      test_2  0.557360  0.570624\n",
       "3      test_3  0.361972  0.412509\n",
       "4      test_4  0.332872  0.345510\n",
       "..        ...       ...       ...\n",
       "452  test_452  0.274158  0.291941\n",
       "453  test_453  0.192220  0.193173\n",
       "454  test_454  0.383139  0.368139\n",
       "455  test_455  0.384266  0.356970\n",
       "456  test_456  0.238958  0.230824\n",
       "\n",
       "[457 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_submission[['Reorg_g', 'Reorg_ex']] = prediction\n",
    "\n",
    "fname = f\"./Submission_Smiles.csv\"\n",
    "sample_submission.to_csv(fname, index=False)\n",
    "print(f\"'{fname}' saved complete.\")\n",
    "\n",
    "display(sample_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Of Program"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "525.994px",
    "width": "422.003px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
